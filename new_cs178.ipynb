{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb8a610",
   "metadata": {
    "id": "43b7d466"
   },
   "source": [
    "# CS178 Final Project\n",
    "Group Members: Zheling Zhang, Jun Yan, Zikang Xiong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5708b4",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset Introduction\n",
    "\n",
    "The dataset our group has chosen was the emotion detection dataset. This project aims to find and fit the most valid model to predict the correct emotions that matches the images from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0edeef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   \n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage import io, color, feature, transform\n",
    "from sklearn import svm, model_selection, metrics\n",
    "\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import requests                                      # reading data\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c380903",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbadb3f9",
   "metadata": {},
   "source": [
    "---\n",
    "## Explore the Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ed408",
   "metadata": {},
   "source": [
    "---\n",
    "## Exploration Technique: Convolutional Neural Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbcddbc",
   "metadata": {},
   "source": [
    "---\n",
    "## Performance Validation with CNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0150a5e1",
   "metadata": {},
   "source": [
    "---\n",
    "## Exploration Technique: Support Vector Machine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d396e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab0964eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img, size=(64, 64), win_size=(64, 64), block_size=(16, 16),\n",
    "                         block_stride=(8, 8), cell_size=(8, 8), nbins=9):\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    img_resized = cv2.resize(img, size)\n",
    "    return hog.compute(img_resized).flatten()\n",
    "\n",
    "def load_dataset(image_paths, labels):\n",
    "    data = []\n",
    "    for img_path, label in zip(image_paths, labels):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        hog_features = extract_hog_features(img)\n",
    "        data.append((hog_features, label))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44ce384",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf46ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = pd.read_csv('data/legend.csv')\n",
    "\n",
    "image_paths = ['images/' + filename for filename in legend.iloc[:, 1]]\n",
    "labels = legend.iloc[:,2].tolist()\n",
    "\n",
    "# This might take ~10s\n",
    "data = load_dataset(image_paths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b78f397",
   "metadata": {},
   "source": [
    "### 2. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2c8b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = zip(*data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee17e461",
   "metadata": {},
   "source": [
    "### 3. Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b621f60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This might take ~1min\n",
    "svm = SVC(kernel='linear', C=1.0)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f51133",
   "metadata": {},
   "source": [
    "### 4. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efa62711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might take ~10s.\n",
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2461fc3",
   "metadata": {},
   "source": [
    "### 5. Performance Validation with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f24ca983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21741dee",
   "metadata": {},
   "source": [
    "### 6. Tuning C Value of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13990620",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_to_tune = SVC(kernel='linear')\n",
    "\n",
    "# Define the range of values to search for C\n",
    "parameters = {'C': [0.1, 1, 10, 100]}\n",
    "# Define the grid search with cross-validation\n",
    "clf = GridSearchCV(svm_to_tune, parameters, cv=2)\n",
    "\n",
    "# This might take ~\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793bb250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best value of C found by grid search\n",
    "print(\"Best C value: \", clf.best_params_['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba13b4c",
   "metadata": {
    "id": "a0921f03"
   },
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
